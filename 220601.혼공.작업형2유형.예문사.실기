# -*- coding: utf-8 -*-
"""
Created on Tue May 31 20:39:01 2022

@author: greenysky
"""
#데이터 불러오기

import pandas as pd
train=pd.read_csv("E:\개발자/304_travel_insurance_train.csv")
test=pd.read_csv("E:\개발자/304_travel_insurance_test.csv")

pd.set_option('display.max_columns', None)    #전체 컬럼을 다보여주는 코드

print(train.info(), test.info())
print(display(train), display(test))   #더 정확히보여준다
print(train.describe, test.describe)   #컬럼이 밀려서 표시됨/None None이 안뜨는 장점 있음
#train.describe
#train.describe()   위아래는 다른 결과. ()있으면 count mean std min등 알수 있음
print(train.head(5), test.head(5))
print(train.columns,'\n','\n', test.columns)
"""
print(train_drop.axes[0].tolist()) #행 명 출력하는 방법
print(train_drop.axes[1].tolist())   #컬럼명 출력하는 방법    
"""
#------------------------------------------------------------------------------------

#데이터 전처리 (라벨링 및 인코딩)

#결측값 확인- 결측값없음
print(train.isnull().sum())
train.isna().sum()   #isnull 과 isna는 같은 함수라고함(구글링)




#음 print(display(train), display(test))으로 보니 Employment Type에서 데이터 종류?가 몇개나 되는지 봐야겠군
#train 에서 employment type 열의 종류 확인
tdg=train.groupby(['Employment Type']).sum()       #groupby 사용법 잘봐두기
print(tdg)


#train.pivot(columns='Employment Type').sum()   #이거보다 위에 groupby가 더 편함
#['Government Sector', 'Private Sector/Self Employed'] 두개가 있구나~
"""
자투리 공부
tdg=train.sort_values(['Employment Type'])       #sort_values는 같은 데이터끼리 정렬
print(tdg)
"""
"""
#train 데이터 전처리

#Employment Type에서 
#'Government Sector'은 0으로
#'Private Sector/Self Employed'은 1로 각각 바꿔줍니다
train_pre=train.copy()
train_pre['Employment Type']=train_pre['Employment Type'].replace(['Government Sector', 'Private Sector/Self Employed'],[0,1])

#yes/no로 구성된 칼럼의 값들을 yes 를 1 no를 0으로 바꿔준다
train_pre['GraduateOrNot']=train_pre['GraduateOrNot'].replace(['Yes','No'],[1,0])
train_pre['FrequentFlyer']=train_pre['FrequentFlyer'].replace(['Yes','No'],[1,0])
train_pre['EverTravelledAbroad']=train_pre['EverTravelledAbroad'].replace(['Yes','No'],[1,0])
print(train_pre)

#test 데이터 전처리
test_pre=test.copy()
test_pre['Employment Type']=test_pre['Employment Type'].replace(['Government Sector', 'Private Sector/Self Employed'],[0,1])

test_pre['GraduateOrNot']=test_pre['GraduateOrNot'].replace(['Yes','No'],[1,0])
test_pre['FrequentFlyer']=test_pre['FrequentFlyer'].replace(['Yes','No'],[1,0])
test_pre['EverTravelledAbroad']=test_pre['EverTravelledAbroad'].replace(['Yes','No'],[1,0])
print(test_pre)

#여기서 ID, TravelInsurance 컬럼을 드랍해준다
train_pre=train_pre.drop(['ID','TravelInsurance'],axis=1)
test_pre=test_pre.drop(['ID'],axis=1)
print(train_pre , test_pre)
"""


#위에껀 나눠서 전처리
#아래는 concat으로 합쳐서 한꺼번에 전처리 후 다시 데이터 나눈거

#먼저 ID, TravelInsurance 드랍
t1=train.drop(['ID','TravelInsurance'],axis=1)
t2=test.drop(['ID'],axis=1)

a=pd.concat([t1,t2])
a_pre=a.copy()
print(a_pre.isnull().sum())
a_pre['Employment Type']=a_pre['Employment Type'].replace(['Government Sector', 'Private Sector/Self Employed'],[0,1])

a_pre['GraduateOrNot']=a_pre['GraduateOrNot'].replace(['Yes','No'],[1,0])
a_pre['FrequentFlyer']=a_pre['FrequentFlyer'].replace(['Yes','No'],[1,0])
a_pre['EverTravelledAbroad']=a_pre['EverTravelledAbroad'].replace(['Yes','No'],[1,0])
print(a_pre)

#나누기
train_pre=a_pre.iloc[:1490]
test_pre=a_pre.iloc[1490:]
print(train_pre)
print(test_pre)






#이제 train_pre와 test_pre를 스케일링 할차례
from sklearn.preprocessing import MinMaxScaler

mmscaler=MinMaxScaler()

#mmscaler.fit(train_pre)
#x_fin_train=mmscaler.transform(train_pre)
x_fin_train=mmscaler.fit_transform(train_pre)
#한줄로 줄인코드

#mmscaler.fit(test_pre)
#x_fin_test=mmscaler.transform(test_pre)
x_fin_test=mmscaler.fit_transform(test_pre)
#한줄로 줄인코드

print('\n'*4,train_pre_sc, '\n'*4,test_pre_sc,'\n'*2)
print('x_fin_train','\n max:',x_fin_train.max(),'\n min:',x_fin_train.min(),'\n mean:',train_pre_sc.mean(),'\n'*2,)
print('x_fin_test','\n max:', x_fin_test.max(),'\n min:', x_fin_test.min(),'\n mean:', test_pre_sc.mean())
#스케일링 완료 
#모든데이터값 max :1 min: 0으로 최대최소정규화 완료


#y_fin_train 생성
y_fin_train=train['TravelInsurance']
print(y_fin_train)

#예문사에서 알려주는 array 형태확인 
print(x_fin_train.shape)
print(x_fin_test.shape)
print(y_fin_train.shape)






#------------------------------------------------------------------------------------


#머모성 
#머신러닝 모델 함수 생성
#fit(x_train_scaled, y_train)


from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

def make_models(xtrain, xtest, ytrain, ytest):
    model1 = LogisticRegression().fit(xtrain, ytrain)
    print('model1 ', get_scores(model1, xtrain, xtest, ytrain, ytest))
    
    model2 = DecisionTreeClassifier(random_state=0).fit(xtrain.ytrain)
    print('model2 ', get_scores(model2, xtrain, xtest, ytrain, ytest))
    
    for d in range(3,8):
        model2=DecisionTreeClassifier(max_depth=d, random_state=0).fit(xtrain,ytrain)
        print('model2 ', d, get_scores(model2, xtrain, xtest, ytrain, ytest))

    model3 = RandomForestClassifier(random_state=0).fit(xtrain,ytrain)
    print('model3 ', get_scores(model3, xtrain, xtest, ytrain, ytest))

    for d in range(3,8):
        model3=RandomForestClassifier(max_depth=d,random_state=0).fit(xtrain, ytrain)
        print('model3 ', get_scores(model3, xtrain, xtest, ytrain, ytest))

    model4 = XGBClassifier(eval_metric='logloss', use_label_encoder=False).fit(xtrain,ytrain)
    print('model4 ', get_scores(model4, xtrain, xtest, ytrain, ytest))




#성능 평가 지표 함수 생성
#모델의 예측정확도와 모델의 설명력등을 평가하는 지표
#머신러닝 모델 함수 실행시 성능 평가 점수도 함께 나타내기 위해 성능평가지표함수 먼저 생성
#mean_absolute_error(y_train, pred_train)
#roc_auc_score
#실제값과 예측값의 차이가 적을 수록 좋은 모형이다.

from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.metrics import r2_score   #결정계수(모형의 설명력)
import numpy as np

def get_scores(model, xtrain, xtest, ytrain, ytest):
    score=model.score(xtrain, ytrain)
    
    ypred=model.predict(xtest)  #x test로 예측값얻기
    
    mae=mean_absolute_error(ytest,ypred)
    mse=mean_squared_error(ytest,ypred)
    r2=r2_score(ytest,ypred)
    return '{:.4f} {:.4f} {:.4f} {:.4f}'.format(score,mae,mse,r2)



#------------------------------------------------------------------------------------


#x_fin_train과 y_fin_train을 기반으로
#약 25%의 검증 데이터 세트(xtest,ytest)를 추출한다.

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest=train_test_split(x_fin_train, y_fin_train, test_size=0.25,
                                              stratify=y_fin_train, random_state=1234)

print(xtrain.shape, xtest.shape, ytrain.shape, ytest.shape)



#------------------------------------------------------------------------------------

#머신러닝 모델 생성 함수를 실행
make_models(xtrain, xtest, ytrain, ytest)

#
#train에서 TravelInsurance 드랍drop해서 x_train에 넣어주고
#x_test에 ID와 TravelInsurance 를 넣어준다
train_drop=train.drop(['TravelInsurance'],inplace=False, axis=1)
print(train_drop)

#drop 한 데이터 확인해주고
print(display(train_drop), display(test))
